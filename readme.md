# Data Science Practice README

Welcome to your data science learning portfolio! This repository documents your journey through key foundational topics and hands-on practice in data analysis and machine learning using Python. The files cover practical exercises from basic statistical tests and visualizations to advanced regression, regularization, and classification‚Äîall designed to help you build real data science project skills step by step.

***

### üìÅ Folder/File Structure

* `week4_day7.ipynb`: Statistical analysis and linear regression project
* `week5_day1.ipynb`: [Notebooks‚Äîadditional exercises, assumed similar scope]
* `week5_day2.ipynb`: Simple linear regression using scikit-learn
* `week5_day3.ipynb`: Polynomial regression, regularization & California housing project
* `week5_day4.ipynb`: Sigmoid function, logistic regression, and classification basics

***

### üèóÔ∏è Main Concepts & Projects Covered

#### 1. Basic Data Analysis & Visualization (`week4_day7.ipynb`)

* Imported real-life data and performed initial cleaning.
* Used **pandas**, **matplotlib**, and **seaborn** to inspect and visualize data.
* Calculated the correlation between numeric features and plotted a heatmap.
* Conducted gender-based comparison of tips and performed t-tests for statistical difference.
* Built and visualized a linear regression model to predict tips from the total bill.
* Explained outputs: slope, intercept, R¬≤ score, and t-test interpretation in practical terms.

#### 2. Simple Linear Regression (`week5_day2.ipynb`)

* Generated and explored synthetic datasets to understand regression basics.
* Split data into training and test sets with **train_test_split**.
* Built, trained, and evaluated a linear regression with scikit-learn.
* Printed regression coefficients, visualized predictions, and assessed model performance using mean squared error and R¬≤.
* Practiced regression with code refactoring and variations for better understanding.

#### 3. Polynomial Regression & Regularization (`week5_day3.ipynb`)

* Expanded regression to polynomial features (introduced non-linearity).
* Used **PolynomialFeatures** and **LinearRegression** to fit complex curves.
* Implemented and compared regularization methods: **Ridge** and **Lasso** regression.
* Applied these models to both synthetic and real-world housing data (California Housing dataset).
* Visualized and compared prediction quality and explained the need for regularization.
* Evaluated model errors with metrics (mean squared error) and performance charts.

#### 4. Neural Network Activation & Logistic Regression (`week5_day4.ipynb`)

* Implemented the sigmoid activation function‚Äîcore for neural networks and classification.
* Plotted the sigmoid to see how it maps any value to the range (0, 1).
* Generated a synthetic binary classification dataset and built a logistic regression model.
* Trained, predicted, and evaluated performance with accuracy, precision, recall, F1, and classification report.
* Showed how logistic regression is the baseline for many advanced machine learning methods.

***

### üöÄ How to Use

* Open any `.ipynb` file in PyCharm, Jupyter, VS Code, or Google Colab to explore the code and outputs interactively.
* Read code comments and markdown explanations for step-by-step learning.
* Run cells for hands-on understanding‚Äîmost code uses **scikit-learn**, **numpy**, **pandas**, **matplotlib**, and **seaborn** for easy experimentation.

***

### üîç Skills You Practiced

* Data cleaning and inspection
* Data visualization (scatter, heatmap, regression plot)
* Hypothesis testing (t-test)
* Feature engineering (polynomial, categorical)
* Model training/testing/validation
* Metric evaluation and result interpretation
* Basic neural network thinking (sigmoid)